{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2963631",
   "metadata": {},
   "source": [
    "라이브러리 버전 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee47bf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import glob  #glob 모듈의 glob 함수는 사용자가 제시한 조건에 맞는 파일명을 리스트 형식으로 반환한다\n",
    "import tensorflow\n",
    "\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf8d3b7",
   "metadata": {},
   "source": [
    "데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "404eb4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " [\"Now I've heard there was a secret chord\", 'That David played, and it pleased the Lord', \"But you don't really care for music, do you?\"]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*' #os.getenv(x)함수는 환경 변수x의 값을 포함하는 문자열 변수를 반환합니다. txt_file_path 에 \"/root/aiffel/lyricist/data/lyrics/*\" 저장\n",
    "\n",
    "txt_list = glob.glob(txt_file_path) #txt_file_path 경로에 있는 모든 파일명을 리스트 형식으로 txt_list 에 할당\n",
    "\n",
    "raw_corpus = [] \n",
    "\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines() #read() : 파일 전체의 내용을 하나의 문자열로 읽어온다. , splitlines()  : 여러라인으로 구분되어 있는 문자열을 한라인씩 분리하여 리스트로 반환\n",
    "        raw_corpus.extend(raw) # extend() : 리스트함수로 추가적인 내용을 연장 한다.\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23255744",
   "metadata": {},
   "source": [
    "preprocess_sentence() 함수를 활용해 데이터를 정제\n",
    "\n",
    "지나치게 긴 문장은 다른 데이터들이 과도한 Padding을 갖게 하므로 제거합니다. \n",
    "너무 긴 문장은 노래 가사 작사하기에 어울리지 않을 수도 있으므로 문장을 토큰화 했을 때 토큰의 개수가 15개를 넘어가는 문장을 학습 데이터에서 제외하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff2732e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now I've heard there was a secret chord\n",
      "That David played, and it pleased the Lord\n",
      "But you don't really care for music, do you?\n",
      "It goes like this\n",
      "The fourth, the fifth\n",
      "The minor fall, the major lift\n",
      "The baffled king composing Hallelujah Hallelujah\n",
      "Hallelujah\n",
      "Hallelujah\n",
      "Hallelujah Your faith was strong but you needed proof\n"
     ]
    }
   ],
   "source": [
    "# enumerate() 함수를 이용하여 raw_corpus list 내에 저장된 문장과 그 문장의 인덱스를 반환 (인덱스, 문장 순)\n",
    "for idx, sentence in enumerate(raw_corpus):\n",
    "    if len(sentence) == 0: continue   # 길이가 0인 문장은 건너뜁니다.\n",
    "    if sentence[-1] == \":\": continue  # 문장의 끝이 : 인 문장은 건너뜁니다.\n",
    "\n",
    "    if idx > 9: break   # 일단 문장 10개만 확인해 볼 겁니다.\n",
    "        \n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f9e506",
   "metadata": {},
   "source": [
    "특수문자들은 모두 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a40eebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re            \n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()       # 소문자로 바꾸고 양쪽 공백을 삭제\n",
    "  \n",
    "    # 아래 3단계를 거쳐 sentence는 스페이스 1개를 delimeter로 하는 소문자 단어 시퀀스로 바뀝니다.\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)        # 패턴의 특수문자를 만나면 특수문자 양쪽에 공백을 추가\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)                  # 공백 패턴을 만나면 스페이스 1개로 치환\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)  # a-zA-Z?.!,¿ 패턴을 제외한 모든 문자(공백문자까지도)를 스페이스 1개로 치환\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    sentence = '<start> ' + sentence + ' <end>'      # 이전 스텝에서 본 것처럼 문장 앞뒤로 <start>와 <end>를 단어처럼 붙여 줍니다\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27180ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> now i ve heard there was a secret chord <end>',\n",
       " '<start> that david played , and it pleased the lord <end>',\n",
       " '<start> but you don t really care for music , do you ? <end>',\n",
       " '<start> it goes like this <end>',\n",
       " '<start> the fourth , the fifth <end>',\n",
       " '<start> the minor fall , the major lift <end>',\n",
       " '<start> the baffled king composing hallelujah hallelujah <end>',\n",
       " '<start> hallelujah <end>',\n",
       " '<start> hallelujah <end>',\n",
       " '<start> hallelujah your faith was strong but you needed proof <end>']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    if len(sentence) == 0: continue\n",
    "    if sentence[-1] == \":\": continue\n",
    "        \n",
    "    corpus.append(preprocess_sentence(sentence))\n",
    "        \n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "643550dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2   50    5 ...    0    0    0]\n",
      " [   2   17 2639 ...    0    0    0]\n",
      " [   2   36    7 ...   43    3    0]\n",
      " ...\n",
      " [   5   22    9 ...   10 1013    3]\n",
      " [  37   15 9049 ...  877  647    3]\n",
      " [   2    7   34 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7fc7187cdb50>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "def tokenize(corpus):\n",
    "    # 텐서플로우에서 제공하는 Tokenizer 패키지를 생성\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=12000,  # 전체 단어의 개수 \n",
    "        filters=' ',    # 별도로 전처리 로직을 추가할 수 있습니다. 이번에는 사용하지 않겠습니다.\n",
    "        oov_token=\"<unk>\"  # out-of-vocabulary, 사전에 없었던 단어는 어떤 토큰으로 대체할지\n",
    "    )\n",
    "    tokenizer.fit_on_texts(corpus)   # 우리가 구축한 corpus로부터 Tokenizer가 사전을 자동구축하게 됩니다.\n",
    "\n",
    "    # 이후 tokenizer를 활용하여 모델에 입력할 데이터셋을 구축하게 됩니다.\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
    "    # tokenizer는 구축한 사전으로부터 corpus를 해석해 Tensor로 변환합니다.\n",
    "\n",
    "    # 입력 데이터의 시퀀스 길이를 일정하게 맞추기 위한 padding  메소드를 제공합니다.\n",
    "    # maxlen의 디폴트값은 None입니다. 이 경우 corpus의 가장 긴 문장을 기준으로 시퀀스 길이가 맞춰집니다.\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post', maxlen=15)  \n",
    "\n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3425ba",
   "metadata": {},
   "source": [
    "생성된 텐서 데이터를 3번째 행, 15번째 열까지만 출력해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4d76947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2   50    5   91  297   65   57    9  969 6042    3    0    0    0\n",
      "     0]\n",
      " [   2   17 2639  873    4    8   11 6043    6  329    3    0    0    0\n",
      "     0]\n",
      " [   2   36    7   37   15  164  282   28  299    4   47    7   43    3\n",
      "     0]]\n"
     ]
    }
   ],
   "source": [
    "print(tensor[:3, :15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e75b98e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : ,\n",
      "5 : i\n",
      "6 : the\n",
      "7 : you\n",
      "8 : and\n",
      "9 : a\n",
      "10 : to\n"
     ]
    }
   ],
   "source": [
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\n",
    "\n",
    "    if idx >= 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6d95bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2   50    5   91  297   65   57    9  969 6042    3    0    0    0]\n",
      "[  50    5   91  297   65   57    9  969 6042    3    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "src_input = tensor[:, :-1]  # tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성합니다. 마지막 토큰은 <END>가 아니라 <pad>일 가능성이 높습니다.\n",
    "tgt_input = tensor[:, 1:]    # tensor에서 <START>를 잘라내서 타겟 문장을 생성합니다.\n",
    "\n",
    "print(src_input[0])\n",
    "print(tgt_input[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f682812",
   "metadata": {},
   "source": [
    "데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4a98259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(src_input)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
    "\n",
    " # tokenizer가 구축한 단어사전 내 7000개와, 여기 포함되지 않은 0:<pad>를 포함하여 7001개\n",
    " # tokenizer.num_words: 주어진 데이터의 문장들에서 빈도수가 높은 n개의 단어만 선택\n",
    " # tokenize() 함수에서 num_words를 7000개로 선언했기 때문에, tokenizer.num_words의 값은 7000\n",
    "VOCAB_SIZE = tokenizer.num_words + 1   \n",
    "\n",
    "# 준비한 데이터 소스로부터 데이터셋을 만듭니다\n",
    "# 데이터셋에 대해서는 아래 문서를 참고하세요\n",
    "# 자세히 알아둘수록 도움이 많이 되는 중요한 문서입니다\n",
    "# https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((src_input, tgt_input))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcbd866",
   "metadata": {},
   "source": [
    "인공지능 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57d52b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super(TextGenerator, self).__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.drop1 = tf.keras.layers.Dropout(0.3)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.drop1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 1024\n",
    "hidden_size = 2048\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ead2886f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 14, 12001), dtype=float32, numpy=\n",
       "array([[[-2.23714509e-04, -5.30312827e-04, -1.18685020e-04, ...,\n",
       "         -1.62467986e-04, -3.11816839e-04,  1.49765634e-04],\n",
       "        [-1.58310955e-04, -5.06837678e-04, -1.04584524e-05, ...,\n",
       "          6.19778657e-05, -1.06486958e-04,  5.16713422e-04],\n",
       "        [ 1.61828182e-04, -2.55939405e-04, -2.34223946e-04, ...,\n",
       "          2.99016305e-04, -1.97013607e-04,  9.41148435e-04],\n",
       "        ...,\n",
       "        [ 5.64171840e-03,  4.98642679e-03, -1.72415772e-03, ...,\n",
       "          1.56429107e-03, -2.83521134e-03, -2.46723602e-03],\n",
       "        [ 6.07387209e-03,  5.66096976e-03, -2.00654264e-03, ...,\n",
       "          1.65065948e-03, -2.99089262e-03, -3.13015957e-03],\n",
       "        [ 6.37323549e-03,  6.25654310e-03, -2.26178253e-03, ...,\n",
       "          1.70521974e-03, -3.11449287e-03, -3.72121553e-03]],\n",
       "\n",
       "       [[-2.23714509e-04, -5.30312827e-04, -1.18685020e-04, ...,\n",
       "         -1.62467986e-04, -3.11816839e-04,  1.49765634e-04],\n",
       "        [-3.40619794e-04, -8.13873776e-04, -7.70798302e-04, ...,\n",
       "          3.46667453e-04, -1.50243563e-04,  2.94821511e-04],\n",
       "        [-6.86118496e-04, -9.53993294e-04, -9.96095827e-04, ...,\n",
       "          7.79305643e-04, -4.29354026e-04,  2.40165202e-04],\n",
       "        ...,\n",
       "        [ 4.54830332e-03,  4.19624848e-03, -2.12905020e-03, ...,\n",
       "          1.40916638e-03, -2.57595256e-03, -2.24366202e-03],\n",
       "        [ 5.20229852e-03,  4.93632909e-03, -2.33162055e-03, ...,\n",
       "          1.51593762e-03, -2.82236258e-03, -2.90087867e-03],\n",
       "        [ 5.68998372e-03,  5.60146570e-03, -2.51910021e-03, ...,\n",
       "          1.59451913e-03, -3.01469723e-03, -3.50118871e-03]],\n",
       "\n",
       "       [[-2.23714509e-04, -5.30312827e-04, -1.18685020e-04, ...,\n",
       "         -1.62467986e-04, -3.11816839e-04,  1.49765634e-04],\n",
       "        [-2.36455162e-04, -6.85881882e-04, -4.35646325e-05, ...,\n",
       "          1.23345686e-04, -1.75241978e-04, -1.93440064e-04],\n",
       "        [-4.48364735e-05, -7.08135718e-04,  5.15200256e-04, ...,\n",
       "          1.78863556e-04, -1.90150153e-04, -2.84642301e-04],\n",
       "        ...,\n",
       "        [ 5.69891371e-03,  4.93381172e-03, -1.41554896e-03, ...,\n",
       "          1.87448866e-03, -2.97463592e-03, -2.17418745e-03],\n",
       "        [ 6.12810161e-03,  5.59143955e-03, -1.76394440e-03, ...,\n",
       "          1.96427573e-03, -3.14568821e-03, -2.79040565e-03],\n",
       "        [ 6.41836412e-03,  6.17584679e-03, -2.07223394e-03, ...,\n",
       "          2.01096013e-03, -3.27566429e-03, -3.35020432e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-2.23714509e-04, -5.30312827e-04, -1.18685020e-04, ...,\n",
       "         -1.62467986e-04, -3.11816839e-04,  1.49765634e-04],\n",
       "        [-6.39359059e-04, -8.07373086e-04, -1.55707443e-04, ...,\n",
       "         -6.97553332e-05, -5.39517263e-04,  2.59939814e-04],\n",
       "        [-1.23857998e-03, -6.52234943e-04, -1.71952692e-04, ...,\n",
       "         -1.90018487e-04, -1.05389008e-04,  6.24710752e-04],\n",
       "        ...,\n",
       "        [ 9.96792223e-04,  1.22998748e-03, -6.89092092e-04, ...,\n",
       "          1.81109144e-03,  3.71839677e-04,  9.61172627e-04],\n",
       "        [ 2.52174865e-03,  1.91977760e-03, -1.17374607e-03, ...,\n",
       "          2.07365863e-03, -2.30098478e-04,  3.01306602e-04],\n",
       "        [ 3.82129732e-03,  2.64542853e-03, -1.59174984e-03, ...,\n",
       "          2.25962256e-03, -7.74423825e-04, -4.31878201e-04]],\n",
       "\n",
       "       [[-2.23714509e-04, -5.30312827e-04, -1.18685020e-04, ...,\n",
       "         -1.62467986e-04, -3.11816839e-04,  1.49765634e-04],\n",
       "        [-8.51162302e-04, -3.99696670e-04,  1.11417590e-04, ...,\n",
       "         -1.90884384e-04, -3.84074985e-04,  3.13885277e-04],\n",
       "        [-1.11497042e-03, -3.36704135e-04,  1.92656153e-04, ...,\n",
       "          2.97970619e-05, -5.58311935e-04,  1.72188338e-05],\n",
       "        ...,\n",
       "        [-8.18676315e-04, -1.94560783e-03,  5.87511808e-04, ...,\n",
       "         -8.58503976e-04,  2.27067620e-03, -2.99652759e-03],\n",
       "        [-1.12116581e-03, -1.51918258e-03,  4.18754644e-04, ...,\n",
       "         -1.11794937e-03,  2.40216753e-03, -3.34727019e-03],\n",
       "        [-1.48708711e-03, -1.15990010e-03,  6.99943572e-04, ...,\n",
       "         -1.16171897e-03,  2.12640152e-03, -2.86536361e-03]],\n",
       "\n",
       "       [[ 1.05850006e-04, -3.56684643e-04,  1.15778719e-04, ...,\n",
       "          8.88081615e-07,  1.81548763e-04,  2.39160450e-04],\n",
       "        [ 7.55153014e-05, -2.62726011e-04,  5.25926531e-04, ...,\n",
       "         -2.15609936e-04, -9.15481723e-05,  1.62085955e-04],\n",
       "        [-1.64318917e-04, -5.80777705e-04,  8.32355872e-04, ...,\n",
       "         -4.99659160e-04, -8.63089866e-04,  4.63915960e-04],\n",
       "        ...,\n",
       "        [ 1.73971057e-04, -1.11309066e-03,  3.32432427e-03, ...,\n",
       "         -2.11457070e-03, -2.96137272e-03,  2.31078593e-03],\n",
       "        [ 2.84556707e-04, -8.22840375e-04,  4.02036868e-03, ...,\n",
       "         -2.18819035e-03, -2.69835768e-03,  2.59031309e-03],\n",
       "        [ 4.39656753e-04, -4.64627548e-04,  4.86617349e-03, ...,\n",
       "         -2.12091953e-03, -2.04298110e-03,  2.89670122e-03]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed2af6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  12289024  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  25174016  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  33562624  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  24590049  \n",
      "=================================================================\n",
      "Total params: 95,615,713\n",
      "Trainable params: 95,615,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb0bb9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none'\n",
    ")\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6883267b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "686/686 [==============================] - 328s 475ms/step - loss: 3.3546\n",
      "Epoch 2/30\n",
      "686/686 [==============================] - 327s 476ms/step - loss: 2.7562\n",
      "Epoch 3/30\n",
      "686/686 [==============================] - 327s 476ms/step - loss: 2.4023\n",
      "Epoch 4/30\n",
      "686/686 [==============================] - 327s 476ms/step - loss: 2.0931\n",
      "Epoch 5/30\n",
      "686/686 [==============================] - 327s 476ms/step - loss: 1.8263\n",
      "Epoch 6/30\n",
      "686/686 [==============================] - 327s 476ms/step - loss: 1.6068\n",
      "Epoch 7/30\n",
      "686/686 [==============================] - 327s 477ms/step - loss: 1.4341\n",
      "Epoch 8/30\n",
      "686/686 [==============================] - 327s 476ms/step - loss: 1.2999\n",
      "Epoch 9/30\n",
      "686/686 [==============================] - 327s 476ms/step - loss: 1.1999\n",
      "Epoch 10/30\n",
      "686/686 [==============================] - 327s 476ms/step - loss: 1.1246\n",
      "Epoch 11/30\n",
      "686/686 [==============================] - 327s 477ms/step - loss: 1.0699\n",
      "Epoch 12/30\n",
      "686/686 [==============================] - 327s 477ms/step - loss: 1.0307\n",
      "Epoch 13/30\n",
      "686/686 [==============================] - 327s 476ms/step - loss: 1.0035\n",
      "Epoch 14/30\n",
      "686/686 [==============================] - 327s 476ms/step - loss: 0.9846\n",
      "Epoch 15/30\n",
      "686/686 [==============================] - 327s 476ms/step - loss: 0.9701\n",
      "Epoch 16/30\n",
      "686/686 [==============================] - 327s 476ms/step - loss: 0.9598\n",
      "Epoch 17/30\n",
      "686/686 [==============================] - 327s 476ms/step - loss: 0.9509\n",
      "Epoch 18/30\n",
      "686/686 [==============================] - 327s 476ms/step - loss: 0.9441\n",
      "Epoch 19/30\n",
      "686/686 [==============================] - 327s 476ms/step - loss: 0.9382\n",
      "Epoch 20/30\n",
      "686/686 [==============================] - 327s 476ms/step - loss: 0.9337\n",
      "Epoch 21/30\n",
      "686/686 [==============================] - 327s 477ms/step - loss: 0.9299\n",
      "Epoch 22/30\n",
      "686/686 [==============================] - 327s 477ms/step - loss: 0.9270\n",
      "Epoch 23/30\n",
      "686/686 [==============================] - 327s 477ms/step - loss: 0.9239\n",
      "Epoch 24/30\n",
      "686/686 [==============================] - 327s 476ms/step - loss: 0.9221\n",
      "Epoch 25/30\n",
      "686/686 [==============================] - 327s 476ms/step - loss: 0.9193\n",
      "Epoch 26/30\n",
      "686/686 [==============================] - 327s 476ms/step - loss: 0.9170\n",
      "Epoch 27/30\n",
      "686/686 [==============================] - 326s 475ms/step - loss: 0.9151\n",
      "Epoch 28/30\n",
      "686/686 [==============================] - 327s 476ms/step - loss: 0.9152\n",
      "Epoch 29/30\n",
      "686/686 [==============================] - 327s 476ms/step - loss: 0.9127\n",
      "Epoch 30/30\n",
      "686/686 [==============================] - 327s 476ms/step - loss: 0.9111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc686389dc0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam() # Adam은 현재 가장 많이 사용하는 옵티마이저이다. 자세한 내용은 차차 배운다.\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy( # 훈련 데이터의 라벨이 정수의 형태로 제공될 때 사용하는 손실함수이다.\n",
    "    from_logits=True, # 기본값은 False이다. 모델에 의해 생성된 출력 값이 정규화되지 않았음을 손실 함수에 알려준다. 즉 softmax함수가 적용되지 않았다는걸 의미한다. \n",
    "    reduction='none'  # 기본값은 SUM이다. 각자 나오는 값의 반환 원할 때 None을 사용한다.\n",
    ")\n",
    "# 모델을 학습시키키 위한 학습과정을 설정하는 단계이다.\n",
    "model.compile(loss=loss, optimizer=optimizer) # 손실함수와 훈련과정을 설정했다.\n",
    "model.fit(dataset, epochs=30) # 만들어둔 데이터셋으로 모델을 학습한다. 30번 학습을 반복하겠다는 의미다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc8dcf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#문장생성 함수 정의\n",
    "#모델에게 시작 문장을 전달하면 모델이 시작 문장을 바탕으로 작문을 진행\n",
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20): #시작 문자열을 init_sentence 로 받으며 디폴트값은 <start> 를 받는다\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence]) #텍스트 안의 단어들을 숫자의 시퀀스의 형태로 변환\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 단어 하나씩 예측해 문장을 만듭니다\n",
    "    #    1. 입력받은 문장의 텐서를 입력합니다\n",
    "    #    2. 예측된 값 중 가장 높은 확률인 word index를 뽑아냅니다\n",
    "    #    3. 2에서 예측된 word index를 문장 뒤에 붙입니다\n",
    "    #    4. 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마칩니다 (도달 하지 못하였으면 while 루프를 돌면서 다음 단어를 예측)\n",
    "    while True: #루프를 돌면서 init_sentence에 단어를 하나씩 생성성\n",
    "        # 1\n",
    "        predict = model(test_tensor) \n",
    "        # 2\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "        # 3 \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        # 4 \n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated #최종적으로 모델이 생성한 문장을 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6db2c46",
   "metadata": {},
   "source": [
    "가사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0463472f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> he s venus <end> '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> he\") # 시작문장으로 he를 넣어 문장생성 함수 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33e9eb7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love you , liberian girl <end> '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i love\")\n",
    "# generate_text 함수에 lyricist 라 정의한 모델을 이용해서 ilove 로 시작되는 문장을 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b627257d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> we re gonna have to tell him <end> '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> we\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b7a2cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> she s got me runnin round and round <end> '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> she\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e265fc",
   "metadata": {},
   "source": [
    "회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb2091f",
   "metadata": {},
   "source": [
    "작사가 인공지능을 만들어 보았다. 데이터 전처리부터 토크나이즈, 모델, 문장 테스트 트레이닝도 해보았다.\n",
    "모델을 이것 저것 뜯어고쳐보고 싶었지만, 생각보다 시간이 정말 많이 걸려 뜯어고쳐가며 실험해보지는 못했다.\n",
    "가사가 정말 그럴듯하다. 한국어, 스페인어 가사들 또한 이렇게 만들 수 있다고 생각하니 정말 편해보인다. 이번 프로젝트를 통해 쉽게 작사를 할 수 있게 된 것 같다. 데이터 여기저기 다 뜯어봐야지!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b7209d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
